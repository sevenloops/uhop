from __future__ import annotations

from typing import Dict

from .ir import MatMul, FusedMatMulRelu, Relu, Op, Schedule


def lower_to_opencl(op: Op) -> Dict[str, str]:
    """
    Lower supported IR ops to OpenCL C kernel source.

    Returns a dict: {"language": "opencl", "kernel_name": str, "source": str}
    """
    if isinstance(op, MatMul):
        return _lower_matmul(op)
    if isinstance(op, FusedMatMulRelu):
        return _lower_fused_matmul_relu(op)
    if isinstance(op, Relu):
        return _lower_relu(op)
    raise ValueError(f"OpenCL lowering not supported for op: {type(op).__name__}")


def _kernel_header(ts: int, vec: int) -> str:
    return (
        "// Generated by UHOP IR OpenCL lowering (tiled)\n"
        f"#define TS {ts}\n"
        f"#define VEC {max(1, vec)}\n\n"
    )


def _choose_ts(s: Schedule | None) -> int:
    cands = [getattr(s, "tile_m", None), getattr(s, "tile_n", None), getattr(s, "tile_k", None)] if s else []
    cands = [int(x) for x in cands if isinstance(x, int) and x > 0]
    ts = cands[0] if cands else 16
    # normalize to common sizes
    if ts not in (8, 16, 32):
        if ts < 8:
            ts = 8
        elif ts < 16:
            ts = 16
        else:
            ts = 32
    return ts


def _choose_vec(s: Schedule | None) -> int:
    v = getattr(s, "vectorize", None) if s else None
    v = int(v) if isinstance(v, int) else 1
    if v not in (1, 2, 4, 8):
        v = 1
    return v


def _lower_matmul(m: MatMul) -> Dict[str, str]:
    ts = _choose_ts(m.schedule)
    vec = _choose_vec(m.schedule)
    # Simple per-element kernel (correctness-first). Replaces previous tiled kernel which
    # expected caller-provided local sizes and produced incorrect results for small test shapes.
    kern = _kernel_header(ts, vec) + r"""
__kernel void uhop_matmul(
    const int M, const int N, const int K,
    __global const float* A,
    __global const float* B,
    __global float* C)
{
    int row = get_global_id(0);
    int col = get_global_id(1);
    if (row >= M || col >= N) return;
    float acc = 0.0f;
    for (int k = 0; k < K; ++k) {
        acc += A[row * K + k] * B[k * N + col];
    }
    C[row * N + col] = acc;
}
"""
    return {
        "language": "opencl",
        "kernel_name": "uhop_matmul",
        "source": kern,
        "tile": ts,
        "vec": vec,
    }


def _lower_fused_matmul_relu(fr: FusedMatMulRelu) -> Dict[str, str]:
    ts = _choose_ts(fr.schedule)
    vec = _choose_vec(fr.schedule)
    kern = _kernel_header(ts, vec) + r"""
__kernel void uhop_fused_matmul_relu(
    const int M, const int N, const int K,
    __global const float* A,
    __global const float* B,
    __global float* Y)
{
    int row = get_global_id(0);
    int col = get_global_id(1);
    if (row >= M || col >= N) return;
    float acc = 0.0f;
    for (int k = 0; k < K; ++k) {
        acc += A[row * K + k] * B[k * N + col];
    }
    float v = acc;
    Y[row * N + col] = v > 0.0f ? v : 0.0f;
}
"""
    return {
        "language": "opencl",
        "kernel_name": "uhop_fused_matmul_relu",
        "source": kern,
        "tile": ts,
        "vec": vec,
    }


def _lower_relu(r: Relu) -> Dict[str, str]:
    kern = _kernel_header(64, 1) + r"""
__kernel void uhop_relu(
    const int N,
    __global const float* X,
    __global float* Y)
{
    const int i = get_global_id(0);
    if (i < N) {
        float v = X[i];
        Y[i] = v > 0.0f ? v : 0.0f;
    }
}
"""
    return {
        "language": "opencl",
        "kernel_name": "uhop_relu",
        "source": kern,
        "tile": 64,
        "vec": 1,
    }
